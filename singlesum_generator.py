import argparse
import glob
import logging
import os

import numpy as np
import torch

from src.common.score import rouge_scorer
from src.single_summary.singlesum import Summarization
from src.single_summary.translator import build_predictor

DEFAULT_DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

parser = argparse.ArgumentParser()
parser.add_argument(
    "--checkpoint_dir",
    default=None,
    type=str,
    required=True,
    help="The output directory where the model predictions and checkpoints will be written.")
parser.add_argument(
    "--alpha",
    default=0.95,
    type=float,
    help="The value of alpha for the length penalty in the beam search.",
)
parser.add_argument("--input", default='../../input.txt', type=str)
parser.add_argument("--result", default='result.txt', type=str)
parser.add_argument(
    "--beam_size", default=5, type=int, help="The number of beams to start with for each example.",
)
parser.add_argument(
    "--min_length", default=30, type=int, help="Minimum number of tokens for the summaries.",
)
parser.add_argument(
    "--max_length", default=100, type=int, help="Maixmum number of tokens for the summaries.",
)
parser.add_argument(
    "--block_trigram",
    action="store_true",
    help="Whether to block the existence of repeating trigrams in the text generated by beam search.",
)
parser.add_argument(
    "--device", type=str, required=False, default=DEFAULT_DEVICE, help="cuda, cuda:1, cpu etc.",
)

args = parser.parse_args()

logging.basicConfig(level=getattr(logging, 'INFO'))
logger = logging.getLogger(__name__)

checkpoints = list(sorted(glob.glob(os.path.join(args.checkpoint_dir, "checkpointepoch=*.ckpt"), recursive=True)))
logger.info("Load model from %s", checkpoints[-1])
logger.info("Device %s", args.device)
summarizer = Summarization.load_from_checkpoint(checkpoints[-1], map_location=args.device)
logger.info(summarizer.__dict__)

tokenizer = summarizer.tokenizer
model = summarizer.model
model.to(args.device)
model.eval()

symbols = {
    "BOS": tokenizer.vocab["<!#s>"],
    "EOS": tokenizer.vocab["<!#/s>"],
    "PAD": tokenizer.vocab["<!#pad>"],
    "PERIOD": tokenizer.vocab["."],
}

translator = build_predictor(args, tokenizer, symbols, model)
scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'])

rouge1, rougeL, results = [], [], []
with open(args.input) as f:
    for i, line in enumerate(f):
        src, target = line.split('|||||')
        src = src.strip()
        target = target.strip()

        sent_tokenized = tokenizer.encode_plus(src, max_length=512, pad_to_max_length=True, return_tensors="pt")
        sent_tokenized['input_ids'] = sent_tokenized['input_ids'].to(args.device)
        sent_tokenized['attention_mask'] = sent_tokenized['attention_mask'].to(args.device)

        for translate in translator.translate(sent_tokenized):
            pred = tokenizer.decode(translate)

        logger.info("SOURCE: %s", src)
        logger.info("TARGET: %s", target)
        logger.info("PRED: %s", ''.join(pred))

        words_scores = scorer.score(''.join(target), ''.join(pred))
        rouge1.append(words_scores['rouge1'].fmeasure)
        rougeL.append(words_scores['rougeL'].fmeasure)

        is_same = False
        striped_target = ''.join(target.split())
        striped_pred = ''.join(pred.split())
        if striped_target == striped_pred or striped_pred in striped_target:
            is_same = True

        results.append((src, pred, is_same))

logger.info("Rouge1: %f, RougeL: %f" % (np.mean(rouge1), np.mean(rougeL)))
logger.info("Write the result to %s", args.result)
with open(args.result, 'w') as f:
    for src, pred, is_same in results:
        f.write('%s|||||%s|||||%r\n' % (src, pred, is_same))
